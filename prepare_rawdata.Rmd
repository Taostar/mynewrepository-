---
title: "Prepare Raw Data"
author: "Yanao Liu"
output: github_document
---

```{r}

rm(list = ls())
gc()
library(data.table)
#library(devtools)
#install_github("andrewuhl/RollingWindow")
library(RollingWindow)
# install.packages("rbenchmark")
# install.packages("microbenchmark")
library(rbenchmark)
library(microbenchmark)
library(reshape2)
library(h2o)
library(microbenchmark)

library(rpart)
library(rpart.plot)
library(xgboost)
library(caret)
library(Cubist)

fun_divzero = function (x) {
  x[is.infinite(x) | is.na(x)] = 0
  x
}

fun_Fcst.Error.Bias = function (dt = test.dt, fcst = "POS_UNITS_GROSS_reg.pred", target = "POS_UNITS_GROSS"){		
      pred = dt[, fcst, with = F]
      actual = dt[, target, with = F]
      error = sum(abs(pred-actual))/ sum(actual)
      bias = sum(pred)/sum(actual) - 1
      list("Fcst.Error" = error, "Fcst.Bias" = bias)
  }

```

BusCat Seasonal slope & Calendar Info
```{r}
seasonalprofile.buscat = fread("Buscat_POS_Curve.csv",
                               drop = c("V1","WEEK_POS_AVG","ANNUAL_POS_AVG", "loess"),
                               colClasses = list(factor = c("CATEGORY_CD")),
                               stringsAsFactors = T,
                               verbose = F)
setnames(seasonalprofile.buscat, c("WK", "FNLN_POS_PROFILE", "pos.slope"), c("C445_WK_NUM","SEASONAL_PROFILE","SEASONAL_SLOPE"))

dt_calendar = fread("calendar.txt",
                    # colClasses = list(character = c("FINELINE_CD")),
                    stringsAsFactors = T,
                    verbose = F)

```

Read data from Brendan for SKU level and aggregriate variables into Category.
```{r}
base.data = fread("model_data_sku_LOB_GF.txt", header = TRUE, stringsAsFactors = TRUE, colClasses = list(factor = "CATEGORY_CD"))

var.colnames = colnames(base.data)

hier.colnames = c("DIVISION_CD", "DIVISION_NM", "LOB_CD", "LOB_NM", "CATEGORY_CD", "CATEGORY_NM")
attr.colnames = c("KVI_IND", "PRODUCT_TYPE_CD", "ONLINEONLY_IND","OGBB","INVENTORY_TIER","BRAND_TYPE_CD", "PRODUCT_PROFILE","CONSUMER_ROLE")
comp.colnames = c(var.colnames[var.colnames %like% 'TPvLP'],var.colnames[var.colnames %like% 'TPvLY'])
pos.colnames = var.colnames[var.colnames %like% "POS" & !var.colnames %in% comp.colnames]
rtl.colnames = var.colnames[var.colnames %like% "RETAIL_INV|AVG_RTL" & !var.colnames %in% comp.colnames]
# pos.colnames = var.colnames[var.colnames %like% "POS"][!var.colnames[var.colnames %like% "POS"] %in% comp.colnames]
# rtl.colnames = c(var.colnames[var.colnames %like% "RETAIL_INV"], var.colnames[var.colnames %like% "AVG_RTL"][!var.colnames[var.colnames %like% "AVG_RTL"] %in% comp.colnames])




count.buscat = unique(base.data[,.(CATEGORY_CD, C445_WK_STRT_DATE, DEAL_TYPE, FINELINE_CD, COUNT_ASSORT_FNLN, COUNT_NEWSKU_FNLN, COUNT_DWO_FNLN)])[, lapply (.SD, function (x) sum(x, na.rm = T)), keyby = .(CATEGORY_CD, C445_WK_STRT_DATE, DEAL_TYPE), .SDcols = 5:7]
setnames(count.buscat, old = c("COUNT_ASSORT_FNLN", "COUNT_NEWSKU_FNLN", "COUNT_DWO_FNLN"), new = c("COUNT_ASSORT_BUSCAT", "COUNT_NEWSKU_BUSCAT", "COUNT_DWO_BUSCAT"))

holiday.buscat = unique(base.data[,.(C445_WK_STRT_DATE, HOLIDAY, STORE_DAY_CLOSURES)])



fun_buscat = function (dt, varnames, type){
  if (typeof(varnames) != "character") stop("ERROR: Input column names are not characters type!")
  if (type == "sum"){
    return(lapply(dt[,varnames, with = FALSE], function (x) sum(x, na.rm = TRUE)))
  }
  else if (type == "avg"){
    return(lapply(dt[,varnames, with = FALSE], function (x) mean(x, na.rm = TRUE)))
  }
}

sum.colnames = c(pos.colnames, rtl.colnames, "SO_QTY")  
avg.colnames = c("CUBE", "COUNT_INV_GREATERTHAN_0", "COUNT_INV_GREATERTHAN_1")

posrtl.buscat = base.data[,merge(fun_buscat(dt = .SD, varnames = sum.colnames, type = "sum"), fun_buscat(dt = .SD, varnames = avg.colnames, type = "avg")), keyby = .(CATEGORY_CD, C445_WK_STRT_DATE, DEAL_TYPE)]

posrtl.buscat[, `:=` (
                      TPvLP_R52_POS_UNIT_GROSS   = fun_divzero(R52_POS_UNIT_GROSS / LP_R52_POS_UNIT_GROSS),
                      TPvLP_R13_POS_UNIT_GROSS   = fun_divzero(R13_POS_UNIT_GROSS / LP_R13_POS_UNIT_GROSS),
                      TPvLP_R4_POS_UNIT_GROSS    = fun_divzero(R4_POS_UNIT_GROSS / LP_R4_POS_UNIT_GROSS),
                      TPvLY_R13_POS_UNIT_GROSS   = fun_divzero(R13_POS_UNIT_GROSS / LY_R13_POS_UNIT_GROSS),
                      TPvLY_R4_POS_UNIT_GROSS    = fun_divzero(R4_POS_UNIT_GROSS / LY_R4_POS_UNIT_GROSS),
                      
                      TPvLP_R52_POS_DOLLAR_GROSS = fun_divzero(R52_POS_DOLLAR_GROSS / LP_R52_POS_DOLLAR_GROSS),
                      TPvLP_R13_POS_DOLLAR_GROSS = fun_divzero(R13_POS_DOLLAR_GROSS / LP_R13_POS_DOLLAR_GROSS),
                      TPvLP_R4_POS_DOLLAR_GROSS  = fun_divzero(R4_POS_DOLLAR_GROSS / LP_R4_POS_DOLLAR_GROSS),
                      TPvLY_R13_POS_DOLLAR_GROSS = fun_divzero(R13_POS_DOLLAR_GROSS / LY_R13_POS_DOLLAR_GROSS),
                      TPvLY_R4_POS_DOLLAR_GROSS  = fun_divzero(R4_POS_DOLLAR_GROSS / LY_R4_POS_DOLLAR_GROSS),
                      
                      TPvLP_R52_POS_UNIT_NET     = fun_divzero(R52_POS_UNIT_NET / LP_R52_POS_UNIT_NET),
                      TPvLP_R13_POS_UNIT_NET     = fun_divzero(R13_POS_UNIT_NET / LP_R13_POS_UNIT_NET),
                      TPvLP_R4_POS_UNIT_NET      = fun_divzero(R4_POS_UNIT_NET / LP_R4_POS_UNIT_NET),
                      TPvLY_R13_POS_UNIT_NET     = fun_divzero(R13_POS_UNIT_NET / LY_R13_POS_UNIT_NET),
                      TPvLY_R4_POS_UNIT_NET      = fun_divzero(R4_POS_UNIT_NET / LY_R4_POS_UNIT_NET),
                      
                      TPvLP_R52_POS_DOLLAR_NET   = fun_divzero(R52_POS_DOLLAR_NET / LP_R52_POS_DOLLAR_NET),
                      TPvLP_R13_POS_DOLLAR_NET   = fun_divzero(R13_POS_DOLLAR_NET / LP_R13_POS_DOLLAR_NET),
                      TPvLP_R4_POS_DOLLAR_NET    = fun_divzero(R4_POS_DOLLAR_NET / LP_R4_POS_DOLLAR_NET),
                      TPvLY_R13_POS_DOLLAR_NET   = fun_divzero(R13_POS_DOLLAR_NET / LY_R13_POS_DOLLAR_NET),
                      TPvLY_R4_POS_DOLLAR_NET    = fun_divzero(R4_POS_DOLLAR_NET / LY_R4_POS_DOLLAR_NET),
                      
                      TPvLP_R52_AVG_RTL_INV      = fun_divzero(R52_AVG_RTL_INV / LP_R52_AVG_RTL_INV),
                      TPvLP_R13_AVG_RTL_INV      = fun_divzero(R13_AVG_RTL_INV / LP_R13_AVG_RTL_INV),
                      TPvLP_R4_AVG_RTL_INV       = fun_divzero(R4_AVG_RTL_INV / LP_R4_AVG_RTL_INV),
                      TPvLY_R13_AVG_RTL_INV      = fun_divzero(R13_AVG_RTL_INV / LY_R13_AVG_RTL_INV),
                      TPvLY_R4_AVG_RTL_INV       = fun_divzero(R4_AVG_RTL_INV / LY_R4_AVG_RTL_INV),
                      
                      TPvLP_R52_AVG_RTL_INV_DOLLARS = fun_divzero(R52_AVG_RTL_INV_DOLLARS / LP_R52_AVG_RTL_INV_DOLLARS),
                      TPvLP_R13_AVG_RTL_INV_DOLLARS = fun_divzero(R13_AVG_RTL_INV_DOLLARS / LP_R13_AVG_RTL_INV_DOLLARS),
                      TPvLP_R4_AVG_RTL_INV_DOLLARS  = fun_divzero(R4_AVG_RTL_INV_DOLLARS / LP_R4_AVG_RTL_INV_DOLLARS),
                      TPvLY_R13_AVG_RTL_INV_DOLLARS = fun_divzero(R13_AVG_RTL_INV_DOLLARS / LY_R13_AVG_RTL_INV_DOLLARS),
                      TPvLY_R4_AVG_RTL_INV_DOLLARS  = fun_divzero(R4_AVG_RTL_INV_DOLLARS / LY_R4_AVG_RTL_INV_DOLLARS)
            )]

```

Count records as percentage of total Buscat SKUs for different types of products' attributes
```{r}
fun_buscat_perc = function (base.dt, varnames)
                  {
                    unique.dt = unique(base.dt[, c("CATEGORY_CD", "PRODUCT_NUM", varnames), with = F])
                    unique.dt[,INVENTORY_TIER := as.factor(INVENTORY_TIER)]
                    #test[,.SD, keyby = CATEGORY_CD]
                    # i = 1
                    atr.perc.buscat = unique.dt[, .(COUNT_SKUs_PER_CAT = .N), by = CATEGORY_CD]
                    for (atr in varnames) {
                        dt = unique.dt[, c("CATEGORY_CD", "PRODUCT_NUM", atr), with = F]
                        atr.levels = switch(atr, 
                                            KVI_IND = c("Y", "N"),
                                            PRODUCT_TYPE_CD = c("PPK","STD"),
                                            ONLINEONLY_IND = c("Y", "N"),
                                            OGBB = c("","GOOD", "BETTER", "BEST"),
                                            INVENTORY_TIER = c("0","1","2","3","4"),
                                            BRAND_TYPE_CD = c("National","Private Label"),
                                            PRODUCT_PROFILE = c("Job or Joy", "High Ticket Discretionary", "Usable", "Consumable"),
                                            CONSUMER_ROLE = c("Player","Destination","Emerging Destination","Convenience"))
                       atr.names = sapply(atr.levels, function (x) paste(atr, x, "Perc", sep = "_"))     
                       # Calculate each Buscat's each attribute levels' percentage  
                       atr.dt    = dt[,sapply(atr.levels, function (x) {lev.count = .SD[get(atr) == x, .N]; total.count = .N; .(lev.count/total.count)}), keyby = CATEGORY_CD]
                       setnames(atr.dt, atr.levels, atr.names)
                       atr.perc.buscat = merge(atr.perc.buscat, atr.dt, by = "CATEGORY_CD")
                    }
                    return(atr.perc.buscat)
                  }

atrperc.buscat = fun_buscat_perc(base.dt = base.data, varnames = attr.colnames)
# Convert colnum names with space into non space 
setnames(atrperc.buscat, 
         old = c("BRAND_TYPE_CD_Private Label_Perc", "PRODUCT_PROFILE_Job or Joy_Perc", 
                 "PRODUCT_PROFILE_High Ticket Discretionary_Perc", "CONSUMER_ROLE_Emerging Destination_Perc"),
         new = c("BRAND_TYPE_CD_Private_Label_Perc", "PRODUCT_PROFILE_Job_or_Joy_Perc",    
                 "PRODUCT_PROFILE_High_Ticket_Discretionary_Perc", "CONSUMER_ROLE_Emerging_Destination_Perc"))
hier.buscat = unique(base.data[, hier.colnames, with = F])


# for (i in length(atr.levels)){
#   
#   atr.dt = dt[,{lev.count = .SD[get(atr) == atr.levels[[i]], .N]; total.count = .N; .(ratio = lev.count/total.count)}, keyby = CATEGORY_CD]
#   setnames(atr.dt, "ratio", atr.names[[i]] )
# }
```


Combine data.tables together 
```{r}
dt.pos.cat = count.buscat[posrtl.buscat]

setkey(dt_calendar, C445_WK_STRT_DATE)
setkey(dt.pos.cat, C445_WK_STRT_DATE)
dt.pos.cat = dt_calendar[dt.pos.cat]

setkey(seasonalprofile.buscat, CATEGORY_CD, C445_WK_NUM)
setkey(dt.pos.cat, CATEGORY_CD, C445_WK_NUM)
dt.pos.cat = seasonalprofile.buscat[dt.pos.cat]

setkey(atrperc.buscat, CATEGORY_CD)
setkey(dt.pos.cat, CATEGORY_CD)
dt.pos.cat = atrperc.buscat[dt.pos.cat]

setkey(hier.buscat, CATEGORY_CD)
setkey(dt.pos.cat, CATEGORY_CD)
dt.pos.cat = hier.buscat[dt.pos.cat]

setkey(holiday.buscat, C445_WK_STRT_DATE)
setkey(dt.pos.cat, C445_WK_STRT_DATE)
dt.pos.cat = holiday.buscat[dt.pos.cat]

names(dt.pos.cat)

col.hier = c(hier.colnames, "CUBE", names(atrperc.buscat[,!c("CATEGORY_CD","COUNT_SKUs_PER_CAT")])) 
col.calendar = names(dt_calendar)
col.profile = names(seasonalprofile.buscat[,!c("CATEGORY_CD", "C445_WK_NUM")])
col.holiday = names(holiday.buscat[,!c("C445_WK_STRT_DATE")])
col.skuCount = c("COUNT_SKUs_PER_CAT", "COUNT_ASSORT_BUSCAT", "COUNT_NEWSKU_BUSCAT", "COUNT_DWO_BUSCAT")
col.so = "SO_QTY"
col.pos = c("DEAL_TYPE", names(base.data)[names(base.data) %like% "POS"])
col.rtlinv = names(base.data)[names(base.data) %like% "INV" & !names(base.data) %in% "INVENTORY_TIER" ] 

ls.col = list("col.hier" = col.hier, 
              "col.calendar" = col.calendar, 
              "col.profile" = col.profile, 
              "col.holiday" = col.holiday, 
              "col.skuCount" = col.skuCount, 
              "col.so" = col.so, 
              "col.pos" = col.pos, 
              "col.rtlinv" = col.rtlinv)

#setdiff(names(dt.pos.cat), c(col.hier, col.calendar, col.profile, col.holiday, col.skuCount, col.so, col.pos, col.rtlinv))

setcolorder(dt.pos.cat, unlist(ls.col))
# fwrite(dt.pos.cat, "C:/Users/yantao.liu/Desktop/Temp/buscat.rawdata.csv")
rm(list = setdiff(ls(), c("dt.pos.cat", "ls.col")))
```

Create Training and Testing data sets
```{r}
master.dt = dt.pos.cat[,c(ls.col$col.pos[-1:-5], ls.col$col.rtlinv[-1:-4]) := NULL] 
# Focus first on Regualr POS_UNITS_GROSS forecast  
master.dt = master.dt[DEAL_TYPE == factor("REGULAR")]
master.dt[, c("DEAL_TYPE","C445_WK_STRT_DATE") := NULL]

train.dt = master.dt[C445_YR_NUM != 2017]
test.dt = master.dt[C445_YR_NUM == 2017]

y.dep = 46
x.indep = c(5, 7:43, 48:51)

```

Machine learning training from R packages 
```{r}

fun.ml = (
  (POS_UNITS_GROSS) ~
    (CATEGORY_CD)+
    (CATEGORY_NM)+
    (CUBE)+
    (KVI_IND_Y_Perc)+
    (KVI_IND_N_Perc)+
    (PRODUCT_TYPE_CD_PPK_Perc)+
    (PRODUCT_TYPE_CD_STD_Perc)+
    (ONLINEONLY_IND_Y_Perc)+
    (ONLINEONLY_IND_N_Perc)+
    (OGBB__Perc)+
    (OGBB_GOOD_Perc)+
    (OGBB_BETTER_Perc)+
    (OGBB_BEST_Perc)+
    (INVENTORY_TIER_0_Perc)+
    (INVENTORY_TIER_1_Perc)+
    (INVENTORY_TIER_2_Perc)+                         
    (INVENTORY_TIER_3_Perc)+
    (INVENTORY_TIER_4_Perc)+
    (BRAND_TYPE_CD_National_Perc)+
    (BRAND_TYPE_CD_Private_Label_Perc)+
    (PRODUCT_PROFILE_Job_or_Joy_Perc)+
    (PRODUCT_PROFILE_High_Ticket_Discretionary_Perc)+
    (PRODUCT_PROFILE_Usable_Perc)+
    (PRODUCT_PROFILE_Consumable_Perc)+               
    (CONSUMER_ROLE_Player_Perc)+
    (CONSUMER_ROLE_Destination_Perc)+
    (CONSUMER_ROLE_Emerging_Destination_Perc)+
    (CONSUMER_ROLE_Convenience_Perc)+
    (C445_WK_NUM)+
    (C445_YR_NUM)+                                   
    (SEASONAL_PROFILE)+
    (SEASONAL_SLOPE)+
    (HOLIDAY)+
    (STORE_DAY_CLOSURES)+
    (COUNT_SKUs_PER_CAT)+
    (COUNT_ASSORT_BUSCAT)+
    (COUNT_NEWSKU_BUSCAT)+
    (COUNT_DWO_BUSCAT)+
    (SO_QTY)+
    # (DEAL_TYPE)+                                     
    (TOTAL_RETAIL_INV)+
    (TOTAL_RETAIL_INV_DOLLARS)+
    (COUNT_INV_GREATERTHAN_0)+
    (COUNT_INV_GREATERTHAN_1))       


# lm -- Linear Regression Tree Model 
lm.model = lm(fun.ml, data = train.dt)
summary(lm.model)
test.dt$POS_UNITS_GROSS_lm.pred = predict(lm.model, newdata = test.dt)

# rpart -- Regression Tree Model
rt.model = rpart(fun.ml, data = train.dt, cp = .005)
summary(rt.model)
dim(rt.model$frame)[[1]]
rt.varimp = as.data.table(varImp(rt.model), keep.rownames = T)
rpart.plot(rt.model, type = 2, fallen.leaves = F, tweak = 1.3)
test.dt$POS_UNITS_GROSS_rt.pred = predict(rt.model, newdata = test.dt)

# Cubist -- Model Tree Model 
mt.model = cubist(x = train.dt[,x.indep, with = F], y = train.dt$POS_UNITS_GROSS, committees = 3)

mt.model = cubist(x = train.dt[,c(5:32, 34:45), with = F], y = train.dt$POS_UNITS_GROSS, committees = 3)

```

Machine learning training in H20
```{r}
# ls.col$col.pos[-1:-5]
# ls.col$col.rtlinv[-1:-4]

localH2O = h2o.init(nthreads = -1)
h2o.init()

train.h2o = as.h2o(train.dt)
test.h2o = as.h2o(test.dt)



# Regression Model 
regression.model.h2o = h2o.glm(y = y.dep, x = x.indep, training_frame =  train.h2o, family = "gaussian")
h2o.performance(regression.model.h2o)
test.dt$POS_UNITS_GROSS_reg.pred = as.data.table(h2o.predict(regression.model.h2o, test.h2o))

# Random Forest
rf.model.h2o = h2o.randomForest(y= y.dep, x = x.indep, training_frame = train.h2o, ntrees = 1000, mtries = 4, seed = 1122)
h2o.performance(rf.model.h2o)
test.dt$POS_UNITS_GROSS_rf.pred = as.data.table(h2o.predict(rf.model.h2o, test.h2o))

# Gradient Boosting 
gbm.model.h2o = h2o.gbm(y = y.dep, x = x.indep, training_frame = train.h2o, ntrees = 1000, max_depth = 4, learn_rate = 0.01, seed = 1122)
h2o.performance(gbm.model.h2o)
test.dt$POS_UNITS_GROSS_gbm.pred = as.data.table(h2o.predict(gbm.model.h2o, test.h2o))

# Deep learning Neural Network 
dl.model.h2o = h2o.deeplearning(y = y.dep, x = x.indep, training_frame = train.h2o, epochs = 60, hidden = c(100, 100), activation = "Rectifier", seed = 1122)
h2o.performance(dl.model.h2o)
test.dt$POS_UNITS_GROSS_dl.pred = as.data.table(h2o.predict(dl.model.h2o, test.h2o))


```




<!-- Data Visulization & Testing -->
<!-- ```{r} -->

<!-- base.data = base.data[CATEGORY_CD == 306] -->
<!-- fwrite(base.data, file = "C:/Users/yantao.liu/Desktop/Temp/base.data.csv") -->
<!-- base.data[C445_WK_STRT_DATE == "2012-12-30", sum(POS_UNITS_GROSS)] -->
<!-- View(base.data[,.(num.products = length(unique(PRODUCT_NUM)), .N, length(unique(COUNT_DWO_BUSCAT))), by = .(CATEGORY_CD, C445_WK_STRT_DATE, DEAL_TYPE)])   -->
<!-- View(base.data[CATEGORY_CD == '306' & C445_WK_STRT_DATE == '2013-08-18',.(CATEGORY_CD, PRODUCT_NUM, C445_WK_STRT_DATE, FINELINE_CD,COUNT_ASSORT_BUSCAT,COUNT_ASSORT_FNLN, COUNT_DWO_BUSCAT, COUNT_DWO_FNLN, NEW_PCT_OF_ASSORT, DWO_PCT_OF_ASSORT)]) -->

<!-- base.data[,pos.colnames, with = FALSE, by = ] -->
<!-- levels(base.data$BRAND_TYPE_CD) -->
<!-- levels(base.data$PRODUCT_PROFILE) -->
<!-- levels(base.data$CONSUMER_ROLE) -->
<!-- sum.colnames = c("CATEGORY_CD", "C445_WK_STRT_DATE", "DEAL_TYPE", pos.colnames, rtl.colnames) -->
<!-- test = base.data[,sum.colnames, with = FALSE] -->
<!-- base.data[,sum.colnames, with = FALSE, by = .(CATEGORY_CD, C445_WK_STRT_DATE, DEAL_TYPE)] -->
<!-- base.data[,lapply(.SD[pos.colnames, rtl.colnames, with = FALSE], sum), keyby = .(CATEGORY_CD, C445_WK_STRT_DATE, DEAL_TYPE)] -->
<!-- base.data[,.N, by = .(PRODUCT_NUM, DEAL_TYPE, C445_WK_STRT_DATE)] -->

<!-- levels(base.data$BRAND_TYPE_CD) -->
<!-- levels(base.data$KVI_IND) -->
<!-- levels(base.data$PRODUCT_TYPE_CD) -->
<!-- levels(base.data$ONLINEONLY_IND) -->
<!-- levels(base.data$OGBB) -->
<!-- levels(base.data$PRODUCT_PROFILE) -->
<!-- levels(base.data$CONSUMER_ROLE) -->
<!-- ``` -->





